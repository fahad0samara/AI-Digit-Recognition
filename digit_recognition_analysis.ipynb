{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition Analysis\n",
    "\n",
    "This notebook contains comprehensive analysis and visualization of our handwritten digit recognition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import cv2\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def load_data(train_path, test_path):\n",
    "    \"\"\"Load and preprocess training and test data\"\"\"\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    X_train = train_data.drop('label', axis=1)\n",
    "    y_train = train_data['label']\n",
    "    X_test = test_data.drop('label', axis=1)\n",
    "    y_test = test_data['label']\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Load the data\n",
    "X_train, X_test, y_train, y_test = load_data('Train Data.csv', 'Test Data.csv')\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def plot_digit_distribution(y_train):\n",
    "    \"\"\"Plot distribution of digits in training data\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.countplot(data=pd.DataFrame(y_train, columns=['digit']), x='digit')\n",
    "    plt.title('Distribution of Digits in Training Data')\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('static/digit_distribution.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_sample_digits(X_train, y_train, num_samples=10):\n",
    "    \"\"\"Plot sample digits from the dataset\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_samples:\n",
    "            img = X_train[i].reshape(28, 28)\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f'Digit: {y_train.iloc[i]}')\n",
    "            ax.axis('off')\n",
    "    plt.savefig('static/sample_digits.png')\n",
    "    plt.show()\n",
    "\n",
    "# Plot distributions and samples\n",
    "plot_digit_distribution(y_train)\n",
    "plot_sample_digits(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_model(X_train_scaled, y_train):\n",
    "    \"\"\"Train the Random Forest model\"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test_scaled, y_test):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('static/confusion_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# Train and evaluate model\n",
    "model = train_model(X_train_scaled, y_train)\n",
    "y_pred = evaluate_model(model, X_test_scaled, y_test)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'models/digit_model.joblib')\n",
    "joblib.dump(scaler, 'models/scaler.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_feature_importance(model, X_train):\n",
    "    \"\"\"Analyze and visualize feature importance\"\"\"\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': range(X_train.shape[1]),\n",
    "        'importance': model.feature_importances_\n",
    "    })\n",
    "    \n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(20), feature_importance['importance'][:20])\n",
    "    plt.title('Top 20 Most Important Features')\n",
    "    plt.xlabel('Feature Index')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.savefig('static/feature_importance.png')\n",
    "    plt.show()\n",
    "\n",
    "analyze_feature_importance(model, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Misclassification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_misclassifications(X_test, y_test, y_pred):\n",
    "    \"\"\"Analyze and visualize misclassified examples\"\"\"\n",
    "    misclassified = np.where(y_test != y_pred)[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(misclassified) and i < 10:\n",
    "            idx = misclassified[i]\n",
    "            img = X_test.iloc[idx].values.reshape(28, 28)\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f'True: {y_test.iloc[idx]}\\nPred: {y_pred[idx]}')\n",
    "            ax.axis('off')\n",
    "    plt.savefig('static/misclassified_examples.png')\n",
    "    plt.show()\n",
    "\n",
    "analyze_misclassifications(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Confidence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_prediction_confidence(model, X_test_scaled):\n",
    "    \"\"\"Analyze and visualize model prediction confidence\"\"\"\n",
    "    probabilities = model.predict_proba(X_test_scaled)\n",
    "    confidence = np.max(probabilities, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(confidence, bins=50)\n",
    "    plt.title('Distribution of Prediction Confidence')\n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('Count')\n",
    "    plt.savefig('static/confidence_distribution.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate average confidence per digit\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    confidence_by_digit = pd.DataFrame({\n",
    "        'digit': predictions,\n",
    "        'confidence': confidence\n",
    "    }).groupby('digit')['confidence'].mean()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    confidence_by_digit.plot(kind='bar')\n",
    "    plt.title('Average Prediction Confidence by Digit')\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel('Average Confidence')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_prediction_confidence(model, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Visualization with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_interactive_confusion_matrix(y_test, y_pred):\n",
    "    \"\"\"Create interactive confusion matrix using plotly\"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig = px.imshow(cm,\n",
    "                    labels=dict(x=\"Predicted\", y=\"True\", color=\"Count\"),\n",
    "                    x=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],\n",
    "                    y=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "    \n",
    "    fig.update_traces(text=cm, texttemplate=\"%{z}\")\n",
    "    fig.update_layout(title='Interactive Confusion Matrix')\n",
    "    fig.show()\n",
    "\n",
    "create_interactive_confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
